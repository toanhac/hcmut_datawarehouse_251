# Bank Customer Churn Data Warehouse & Decision Support System

A complete Python-based data warehouse and decision support system for analyzing bank customer churn, built for university coursework in "Data Warehouse & Decision Support System".

## ğŸ“Š Project Overview

This project implements a full end-to-end data warehouse solution for bank customer churn analysis, including:

- **Star Schema Data Warehouse** with dimension and fact tables
- **ETL Pipeline** for data extraction, transformation, and loading
- **Machine Learning Model** for churn prediction
- **Python-based Visualizations** for exploratory analysis and reporting
- **SQL Queries** for OLAP-style analytics

## ğŸ—‚ï¸ Project Structure

```
bank_churn_dwh_dss/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw dataset (Churn_Modelling.csv)
â”‚   â”œâ”€â”€ interim/                # Cleaned, preprocessed data
â”‚   â””â”€â”€ processed/              # Dimension and fact tables (CSV)
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_dwh_schema.sql   # DDL for star schema
â”‚   â””â”€â”€ olap_queries.sql        # Sample OLAP queries
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # Configuration and paths
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ load_raw.py         # Load raw CSV
â”‚   â”‚   â”œâ”€â”€ preprocess.py       # Data cleaning & feature engineering
â”‚   â”‚   â””â”€â”€ dwh_etl.py          # Build dimension/fact tables
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ eda_plots.py        # Exploratory data analysis plots
â”‚   â”‚   â””â”€â”€ churn_dashboard_plots.py  # Dashboard-style plots
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ churn_model.py      # ML model training
â”‚       â””â”€â”€ evaluation.py       # Model evaluation
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda_and_cleaning.ipynb
â”‚   â”œâ”€â”€ 02_build_dwh_and_olap.ipynb
â”‚   â””â”€â”€ 03_churn_modeling_and_viz.ipynb
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                # Generated PNG plots
â””â”€â”€ README.md
```

## ğŸ“¦ Dataset

**Source**: Kaggle - Bank Customer Churn Modeling  
**File**: `Churn_Modelling.csv`  
**Size**: 10,000 rows Ã— 14 columns

### Columns:
- `RowNumber`, `CustomerId`, `Surname` (dropped during preprocessing)
- `CreditScore`, `Geography`, `Gender`, `Age`, `Tenure`
- `Balance`, `NumOfProducts`, `HasCrCard`, `IsActiveMember`
- `EstimatedSalary`, `Exited` (target variable: 0=Retained, 1=Churned)

**âš ï¸ Important**: Download the dataset from Kaggle and place it at:  
`data/raw/Churn_Modelling.csv`

## ğŸ—ï¸ Data Warehouse Design

### Star Schema

**Fact Table**: `fact_customer_status`
- Grain: One row per customer snapshot
- Measures: `balance`, `estimated_salary`, `num_of_products`, `credit_score`
- Flags: `has_credit_card`, `is_active_member`, `churn_flag`
- Foreign Keys: `customer_key`, `time_key`, `geo_key`, `segment_key`

**Dimension Tables**:
- `dim_customer`: Customer demographics (age, gender, tenure)
- `dim_geo`: Geography (country)
- `dim_time`: Snapshot time (year, month, quarter)
- `dim_segment`: Customer segments (age group, income group)

## ğŸš€ Getting Started

### Prerequisites

```bash
# Python 3.11+ required
python --version

# Install required packages
pip install pandas numpy matplotlib scikit-learn

# For interactive dashboard (optional)
pip install dash plotly
```

### Setup

1. **Clone/Download** this project
2. **Download dataset** from Kaggle and place at `data/raw/Churn_Modelling.csv`
3. **Create directories**:
   ```bash
   cd bank_churn_dwh_dss
   python src/config.py
   ```

### Running the Pipeline

#### Option 1: Run Python Modules Directly

```bash
# Step 1: Load and preprocess data
python src/data/load_raw.py
python src/data/preprocess.py

# Step 2: Build data warehouse
python src/data/dwh_etl.py

# Step 3: Generate visualizations
python src/visualization/eda_plots.py
python src/visualization/churn_dashboard_plots.py

# Step 4: Train and evaluate model
python src/models/churn_model.py
python src/models/evaluation.py
```

#### Option 2: Use Jupyter Notebooks

```bash
jupyter notebook
```

Then run notebooks in order:
1. `01_eda_and_cleaning.ipynb` - Data exploration and preprocessing
2. `02_build_dwh_and_olap.ipynb` - Build DWH and run OLAP queries
3. `03_churn_modeling_and_viz.ipynb` - Train ML model and generate visualizations

#### Option 3: Interactive Dashboard (Recommended!)

```bash
# Launch the interactive web dashboard
python run_dashboard.py
```

Then open your browser to: **http://localhost:8050**

**Dashboard Features:**
- ğŸ“Š Real-time KPI cards (Total Customers, Churned, Churn Rate, Avg Balance)
- ğŸ” Interactive filters (Country, Age Group, Gender)
- ğŸ“ˆ 6 interactive charts:
  - Churn Rate by Country
  - Churn Rate by Age Group
  - Balance Distribution by Churn Status
  - Churn Rate by Number of Products
  - Customer Age Distribution
  - Churn Rate by Tenure
- ğŸ¨ Modern, responsive UI with Plotly visualizations

## ğŸ“ˆ Outputs

### Generated Files

**Data Files** (in `data/processed/`):
- `dim_customer.csv`
- `dim_geo.csv`
- `dim_time.csv`
- `dim_segment.csv`
- `fact_customer_status.csv`

**Visualizations** (in `reports/figures/`):
- `churn_distribution.png` - Overall churn distribution
- `age_distribution.png` - Age distribution histogram
- `churn_by_geography.png` - Churn rate by country
- `balance_by_churn.png` - Average balance comparison
- `churn_by_age_group.png` - Churn rate by age group
- `churn_by_products.png` - Churn rate by number of products
- `feature_importance.png` - ML model feature importance
- `confusion_matrix.png` - Model evaluation confusion matrix

## ğŸ¤– Machine Learning

### Model: Logistic Regression (Baseline)

**Features**:
- Numeric: `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, `EstimatedSalary`
- Categorical: `Geography`, `Gender`

**Preprocessing**:
- StandardScaler for numeric features
- OneHotEncoder for categorical features

**Evaluation Metrics**:
- Accuracy
- Confusion Matrix
- Classification Report (Precision, Recall, F1-Score)
- ROC-AUC Score

### Optional: Random Forest

Change model type in `churn_model.py`:
```python
model, X_train, X_test, y_train, y_test, feature_names = train_model(df, model_type='random_forest')
```

## ğŸ“Š SQL Queries

The `sql/olap_queries.sql` file contains 12 analytical queries, including:
- Overall churn rate
- Churn rate by country, age group, income group
- Average balance by churn status
- Customer profile comparison
- High-value customer analysis
- And more...

To use these queries, load the CSV files into a PostgreSQL database using the schema in `sql/create_dwh_schema.sql`.

## ğŸ“ Educational Value

This project demonstrates:
- âœ… Data warehouse dimensional modeling (star schema)
- âœ… ETL pipeline design and implementation
- âœ… Data preprocessing and feature engineering
- âœ… OLAP-style analytical queries
- âœ… Machine learning for predictive analytics
- âœ… Data visualization for decision support
- âœ… Clean code organization and modularity

## ğŸ“ License

This project is for educational purposes as part of university coursework.

## ğŸ‘¤ Author



## ğŸ™ Acknowledgments

- Dataset: Kaggle Bank Customer Churn Modeling
- Course: Data Warehouse & Decision Support System
