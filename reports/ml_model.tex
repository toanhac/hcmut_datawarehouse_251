\section{Mô hình dự đoán churn (Machine Learning)}

\subsection{Tổng quan về bài toán}

Bài toán dự đoán churn là một bài toán phân loại nhị phân (binary classification):
\begin{itemize}
    \item \textbf{Input}: Các đặc trưng của khách hàng (CreditScore, Age, Balance, Geography, Gender, v.v.)
    \item \textbf{Output}: Dự đoán khách hàng có churn hay không (0 hoặc 1)
    \item \textbf{Mục tiêu}: Tối đa hóa độ chính xác và khả năng phát hiện khách hàng có nguy cơ churn cao
\end{itemize}

\subsection{Chuẩn bị dữ liệu cho modeling}

\subsubsection{Chọn features}

Từ dữ liệu gốc, ta chọn các features sau:

\textbf{Numeric features}:
\begin{itemize}
    \item CreditScore: Điểm tín dụng
    \item Age: Tuổi
    \item Tenure: Số năm sử dụng dịch vụ
    \item Balance: Số dư tài khoản
    \item NumOfProducts: Số lượng sản phẩm
    \item EstimatedSalary: Mức lương ước tính
    \item HasCrCard: Có thẻ tín dụng (0/1)
    \item IsActiveMember: Thành viên hoạt động (0/1)
\end{itemize}

\textbf{Categorical features}:
\begin{itemize}
    \item Geography: Quốc gia (France, Germany, Spain)
    \item Gender: Giới tính (Male, Female)
\end{itemize}

\textbf{Target variable}:
\begin{itemize}
    \item Exited: Trạng thái churn (0=Retained, 1=Churned)
\end{itemize}

\subsubsection{Chia tập train/test}

\begin{lstlisting}[style=python]
from sklearn.model_selection import train_test_split

# Doc du lieu
df = pd.read_csv('data/raw/Churn_Modelling.csv')

# Chon features va target
features = ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 
            'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 
            'EstimatedSalary']
X = df[features]
y = df['Exited']

# Chia train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train set: {len(X_train)} samples")
print(f"Test set: {len(X_test)} samples")
\end{lstlisting}

\subsection{Preprocessing Pipeline}

Sử dụng \texttt{scikit-learn Pipeline} để xử lý dữ liệu tự động:

\begin{lstlisting}[style=python]
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Dinh nghia cac cot numeric va categorical
numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 
                    'NumOfProducts', 'EstimatedSalary']
categorical_features = ['Geography', 'Gender']
binary_features = ['HasCrCard', 'IsActiveMember']

# Tao preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features),
        ('bin', 'passthrough', binary_features)
    ]
)
\end{lstlisting}

\textbf{Giải thích}:
\begin{itemize}
    \item \textbf{StandardScaler}: Chuẩn hóa các biến số về mean=0, std=1, giúp mô hình hội tụ nhanh hơn.
    \item \textbf{OneHotEncoder}: Chuyển biến phân loại thành dạng one-hot encoding (ví dụ: Geography thành 2 cột Germany, Spain).
    \item \textbf{Passthrough}: Giữ nguyên các biến nhị phân (HasCrCard, IsActiveMember).
\end{itemize}

\subsection{Xây dựng mô hình}

\subsubsection{Mô hình 1: Logistic Regression}

Logistic Regression là mô hình baseline đơn giản nhưng hiệu quả cho bài toán phân loại nhị phân.

\begin{lstlisting}[style=python]
from sklearn.linear_model import LogisticRegression

# Tao pipeline
lr_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

# Train model
lr_pipeline.fit(X_train, y_train)

# Du doan
y_pred = lr_pipeline.predict(X_test)
y_pred_proba = lr_pipeline.predict_proba(X_test)[:, 1]
\end{lstlisting}

\subsubsection{Mô hình 2: Random Forest}

Random Forest là mô hình ensemble mạnh mẽ, có thể capture các mối quan hệ phi tuyến.

\begin{lstlisting}[style=python]
from sklearn.ensemble import RandomForestClassifier

# Tao pipeline
rf_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, 
                                          random_state=42))
])

# Train model
rf_pipeline.fit(X_train, y_train)

# Du doan
y_pred_rf = rf_pipeline.predict(X_test)
\end{lstlisting}

\subsection{Đánh giá mô hình}

\subsubsection{Accuracy}

\begin{lstlisting}[style=python]
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
\end{lstlisting}

\textbf{Kết quả}: Logistic Regression đạt accuracy khoảng 80-81\%.

\subsubsection{Confusion Matrix}

\begin{lstlisting}[style=python]
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.savefig('reports/figures/confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()
\end{lstlisting}

\begin{figure}[h!]
\centering
\includegraphics[width=0.6\textwidth]{figures/confusion_matrix.png}
\caption{Confusion Matrix của mô hình Logistic Regression}
\label{fig:confusion_matrix}
\end{figure}

\textbf{Phân tích Confusion Matrix}:
\begin{itemize}
    \item \textbf{True Negative (TN)}: Số khách hàng không churn được dự đoán đúng (~1500).
    \item \textbf{False Positive (FP)}: Số khách hàng không churn bị dự đoán nhầm là churn (~100).
    \item \textbf{False Negative (FN)}: Số khách hàng churn bị dự đoán nhầm là không churn (~300).
    \item \textbf{True Positive (TP)}: Số khách hàng churn được dự đoán đúng (~100).
\end{itemize}

\subsubsection{Classification Report}

\begin{lstlisting}[style=python]
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred, target_names=['Retained', 'Churned']))
\end{lstlisting}

\textbf{Kết quả mẫu}:
\begin{verbatim}
              precision    recall  f1-score   support

    Retained       0.83      0.94      0.88      1600
     Churned       0.56      0.25      0.35       400

    accuracy                           0.81      2000
   macro avg       0.70      0.60      0.62      2000
weighted avg       0.78      0.81      0.78      2000
\end{verbatim}

\textbf{Nhận xét}:
\begin{itemize}
    \item \textbf{Precision cho Churned}: 56\% - Trong số khách hàng được dự đoán là churn, chỉ 56\% thực sự churn.
    \item \textbf{Recall cho Churned}: 25\% - Mô hình chỉ phát hiện được 25\% khách hàng churn thực tế.
    \item \textbf{F1-score cho Churned}: 0.35 - Khá thấp, cho thấy mô hình còn yếu trong việc dự đoán churn.
\end{itemize}

\subsubsection{ROC-AUC Score}

\begin{lstlisting}[style=python]
from sklearn.metrics import roc_auc_score, roc_curve

auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC-AUC Score: {auc:.4f}")

# Ve duong ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.savefig('reports/figures/roc_curve.png', dpi=300, bbox_inches='tight')
plt.close()
\end{lstlisting}

\textbf{Kết quả}: ROC-AUC khoảng 0.85-0.86, cho thấy mô hình có khả năng phân biệt tốt giữa churn và không churn.

\subsection{Feature Importance}

Với Random Forest, ta có thể xem feature importance:

\begin{lstlisting}[style=python]
# Lay feature importance
importances = rf_pipeline.named_steps['classifier'].feature_importances_

# Lay ten features sau khi preprocessing
feature_names = (numeric_features + 
                 list(rf_pipeline.named_steps['preprocessor']
                      .named_transformers_['cat'].get_feature_names_out()) +
                 binary_features)

# Sap xep
indices = np.argsort(importances)[::-1][:10]

# Ve bieu do
plt.figure(figsize=(10, 6))
plt.bar(range(10), importances[indices])
plt.xticks(range(10), [feature_names[i] for i in indices], rotation=45, ha='right')
plt.title('Top 10 Feature Importance - Random Forest')
plt.ylabel('Importance')
plt.tight_layout()
plt.savefig('reports/figures/feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()
\end{lstlisting}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{figures/feature_importance.png}
\caption{Top 10 features quan trọng nhất trong mô hình Random Forest}
\label{fig:feature_importance}
\end{figure}

\textbf{Nhận xét}: Age, NumOfProducts, và Balance thường là những features quan trọng nhất trong dự đoán churn.
